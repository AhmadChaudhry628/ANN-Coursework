# -*- coding: utf-8 -*-
"""Anomaly-Detection-Using-Ann.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13cBisjmfk0Hipz1kdnWQyrW4lzVF3gLH
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Input, Dense, LSTM, Dropout,Reshape
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import accuracy_score, precision_score, f1_score

# Load the dataset
df = pd.read_csv('./dataset/ETH_day.csv')
print(df.columns)
# Rename the columns
df = df.rename(columns={'Date': 'date', 'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume ETH': 'volume_eth', 'Volume USD': 'volume_usd'})

# Drop unnecessary columns
df = df[['date', 'open', 'high', 'low', 'close', 'volume_eth', 'volume_usd']]

# Set the date column as the index
df['date'] = pd.to_datetime(df['date'])
df.set_index('date', inplace=True)

# Resample the data to daily frequency
df = df.resample('D').mean()

# Select the relevant features
relevant_features = ['open', 'high', 'low', 'close', 'volume_eth', 'volume_usd']
df = df[relevant_features]

# Normalize the data
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df.values)

# Define the sequence length and number of features
sequence_length = 30
num_features = len(relevant_features)

# Split the data into training and testing sets
train_size = int(0.7 * len(scaled_data))
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size-sequence_length:]

# Define the input and output sequences for the training set
train_X = []
train_y = []
for i in range(sequence_length, len(train_data)):
    train_X.append(train_data[i-sequence_length:i])
    train_y.append(train_data[i])

# Convert the input and output sequences to numpy arrays
train_X = np.array(train_X)
train_y = np.array(train_y)

# Define the input and output sequences for the testing set
test_X = []
test_y = []
for i in range(sequence_length, len(test_data)):
    test_X.append(test_data[i-sequence_length:i])
    test_y.append(test_data[i])

# Convert the input and output sequences to numpy arrays
test_X = np.array(test_X)
test_y = np.array(test_y)

# Define the LSTM model architecture
lstm_model = Sequential()
lstm_model.add(LSTM(units=128, input_shape=(sequence_length, num_features), return_sequences=True))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(units=128, return_sequences=True))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(units=128))
lstm_model.add(Dropout(0.2))
lstm_model.add(Dense(units=num_features))
lstm_model.summary()

# Compile the LSTM model
lstm_model.compile(optimizer='adam', loss='mse')

# Define early stopping criteria for LSTM model
early_stopping_lstm = EarlyStopping(monitor='val_loss', patience=5)

# Train the LSTM model
history_lstm = lstm_model.fit(train_X, train_y, epochs=50, batch_size=32, validation_data=(test_X, test_y), callbacks=[early_stopping_lstm])

# Plot the training and testing loss for LSTM model
plt.plot(history_lstm.history['loss'], label='train_loss')
plt.plot(history_lstm.history['val_loss'], label='test_loss')
plt.title('LSTM Model Training and Testing Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions using the LSTM model on the test set
predictions_lstm = lstm_model.predict(test_X)

# Compute the mean squared error of the predictions
mse_lstm = np.mean(np.power(test_y - predictions_lstm, 2), axis=1)

# Compute the mean squared error threshold for anomaly detection
mse_threshold_lstm = np.mean(mse_lstm) + np.std(mse_lstm)

# Detect the anomalies in the test set using the LSTM model
anomalies_lstm = np.where(mse_lstm > mse_threshold_lstm)[0]

# Plot the predicted and actual values of the test set using the LSTM model
plt.plot(test_y[:, 0], label='actual')
plt.plot(predictions_lstm[:, 0], label='predicted')
plt.xlabel('Time')
plt.ylabel('Normalized price')
plt.title('LSTM Model Predictions')
plt.legend()
plt.show()

# Plot the mean squared error of the test set using the LSTM model
plt.plot(mse_lstm)
plt.axhline(y=mse_threshold_lstm, color='r', linestyle='-')
plt.xlabel('Time')
plt.ylabel('MSE')
plt.title('LSTM Model Mean Squared Error')
plt.show()

# Plot the anomalies in the test set using the LSTM model
plt.plot(test_y[:, 0], label='actual')
plt.scatter(anomalies_lstm, test_y[anomalies_lstm, 0], color='r', label='anomaly')
plt.xlabel('Time')
plt.ylabel('Normalized price')
plt.title('LSTM Model Anomalies')
plt.legend()
plt.show()

# Define the autoencoder model architecture
inputs = Input(shape=(sequence_length, num_features))
x = LSTM(128, return_sequences=True)(inputs)
x = Dropout(0.2)(x)
x = LSTM(128, return_sequences=True)(x)
x = Dropout(0.2)(x)
x = LSTM(128)(x)
x = Dropout(0.2)(x)
encoded = Dense(64, activation='relu')(x)
x = Reshape((1, 64))(encoded)
x = Dense(128, activation='relu')(x)
x = Dropout(0.2)(x)
x = LSTM(128, return_sequences=True)(x)
x = Dropout(0.2)(x)
x = LSTM(128, return_sequences=True)(x)
x = Dropout(0.2)(x)
decoded = LSTM(num_features, return_sequences=True)(x)
autoencoder = Model(inputs, decoded)
autoencoder.summary()

# Compile the autoencoder model
autoencoder.compile(optimizer='adam', loss='mse')
# define early stopping callback
early_stopping_ae = EarlyStopping(monitor='val_loss', patience=5)

# Train the autoencoder model
history_ae = autoencoder.fit(train_X, train_X, epochs=50, batch_size=32, validation_data=(test_X, test_X), callbacks=[early_stopping_ae])

# Plot the training and testing loss for the autoencoder
plt.plot(history_ae.history['loss'], label='train_loss_ae')
plt.plot(history_ae.history['val_loss'], label='test_loss_ae')
plt.title('Training and Testing Loss (Autoencoder)')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions on the test set using the autoencoder
encoded_X = autoencoder.predict(test_X)

# Compute the mean squared error of the encoded data
mse_ae = np.mean(np.power(test_X - encoded_X, 2), axis=1)

# Compute the mean squared error threshold for anomaly detection

mse_ae_threshold = np.mean(mse_ae) + np.std(mse_ae)

# Detect the anomalies in the test set using the autoencoder
anomalies_ae = np.where(mse_ae > mse_ae_threshold)[0]

# Plot the anomalies in the test set using the autoencoder
plt.plot(test_y[:, 0], label='actual')
plt.scatter(anomalies_ae, test_y[anomalies_ae, 0], color='r', label='anomaly (autoencoder)')
plt.xlabel('Time')
plt.ylabel('Normalized price')
plt.legend()
plt.show()

# Plot the mean squared error of the test set using the autoencoder
plt.plot(mse_ae)
plt.axhline(y=mse_ae_threshold, color='r', linestyle='-')
plt.xlabel('Time')
plt.ylabel('MSE (autoencoder)')
plt.show()

# Plot the predicted and actual values of the test set using the autoencoder
decoded_X = autoencoder.predict(test_X)
plt.plot(test_y[:, 0], label='actual')
plt.plot(decoded_X[:, :, 0].flatten(), label='predicted (autoencoder)')
plt.xlabel('Time')
plt.ylabel('Normalized price')
plt.legend()
plt.show()

# Calculate the TPR for the LSTM model
total_anomalies = len(np.where(test_y[:, 0] > mse_threshold_lstm)[0])
correct_anomalies = len(anomalies_lstm)
lstm_tpr = correct_anomalies / total_anomalies
print('LSTM Model TPR: {:.2%}'.format(lstm_tpr))


# Calculate the TPR for the autoencoder model
total_anomalies = len(np.where(test_y[:, 0] > mse_ae_threshold)[0])
correct_anomalies = len(anomalies_ae)
autoencoder_tpr = correct_anomalies / total_anomalies
print('Autoencoder Model TPR: {:.2%}'.format(autoencoder_tpr))